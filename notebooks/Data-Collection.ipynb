{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4572ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0f98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_vectorstock(directory, start_page, end_page):\n",
    "    url = 'https://www.vectorstock.com/royalty-free-vectors/owl-sketch-vectors'\n",
    "    \n",
    "    print('Checking if {} exists.'.format(directory))\n",
    "    if not os.path.isdir(directory):\n",
    "        print('Creating {}.'.format(directory))\n",
    "        os.mkdir(directory)\n",
    "        print('{} created.'.format(directory))\n",
    "    else:\n",
    "        print('{} exists.'.format(directory))\n",
    "    \n",
    "    directory_tail = 'Page_{:02d}-{:02d}'.format(start_page, end_page)\n",
    "    subdirectory = directory + '/' + directory_tail\n",
    "    if not os.path.isdir(subdirectory):\n",
    "        print('Creating subdirectory {}.'.format(subdirectory))\n",
    "        os.mkdir(subdirectory)\n",
    "        print('{} subdirectory created.'.format(subdirectory))\n",
    "    else:\n",
    "        print('Subdirectory {} exists.'.format(subdirectory))\n",
    "    \n",
    "    page_range = range(start_page, end_page + 1)\n",
    "    \n",
    "    for page in page_range:\n",
    "        time.sleep(0.1)\n",
    "        url_tail = '-page_{}'.format(page)\n",
    "        print('Scraping page {}'.format(page))\n",
    "        response = requests.get(url + url_tail)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        image_tags = soup.find_all('img')\n",
    "        \n",
    "        for index, image in enumerate(image_tags):\n",
    "            time.sleep(0.1)\n",
    "            print('Saving image {} of {} to {}.'.format(index + 1, len(image_tags), subdirectory))\n",
    "            img = Image.open(requests.get(image['src'], stream = True).raw)\n",
    "            img_name = 'VectorStock_Page_{:02d}_Image_{:03d}.{}'.format(page, index + 1, img.format)\n",
    "            img.save(subdirectory + '/' + img_name)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25275f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_adobe(directory, start_page, end_page, subcategory_url_string, subcategory_title):\n",
    "    url = 'https://stock.adobe.com/search/images?&k=owl+{}'.format(subcategory_url_string)\n",
    "    \n",
    "    print('Checking if {} exists.'.format(directory))\n",
    "    if not os.path.isdir(directory):\n",
    "        print('Creating {}.'.format(directory))\n",
    "        os.mkdir(directory)\n",
    "        print('{} created.'.format(directory))\n",
    "    else:\n",
    "        print('{} exists.'.format(directory))\n",
    "    \n",
    "    directory_tail = 'Page_{:03d}-{:03d}'.format(start_page, end_page)\n",
    "    subdirectory = directory + '/' + directory_tail\n",
    "    if not os.path.isdir(subdirectory):\n",
    "        print('Creating subdirectory {}.'.format(subdirectory))\n",
    "        os.mkdir(subdirectory)\n",
    "        print('{} subdirectory created.'.format(subdirectory))\n",
    "    else:\n",
    "        print('Subdirectory {} exists.'.format(subdirectory))\n",
    "    \n",
    "    page_range = range(start_page, end_page + 1)\n",
    "    \n",
    "    for page in page_range:\n",
    "        time.sleep(0.1)\n",
    "        url_tail = '&search_page={}'.format(page)\n",
    "        print('Scraping page {}'.format(page))\n",
    "        response = requests.get(url + url_tail)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        image_tags = soup.find_all('img')\n",
    "        image_tags_cleaned = [x for x in image_tags if 'data-lazy' in\\\n",
    "                              x.attrs.keys() or x['src'].endswith('.jpg')]\n",
    "        \n",
    "        for index, image in enumerate(image_tags_cleaned):\n",
    "            time.sleep(0.1)\n",
    "            if 'data-lazy' in image.attrs.keys():\n",
    "                img = Image.open(requests.get(image['data-lazy'], stream = True).raw)\n",
    "            elif image['src'].endswith('.jpg'):\n",
    "                img = Image.open(requests.get(image['src'], stream = True).raw)\n",
    "            print('Saving image {} of {} to {}.'.format(index + 1, len(image_tags_cleaned), subdirectory))\n",
    "            img_name = 'AdobeStock{}_Page_{:03d}_Image_{:03d}.{}'.format(subcategory_title, \n",
    "                                                                         page, index + 1, img.format)\n",
    "            img.save(subdirectory + '/' + img_name)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5859e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fineartamerica(directory, start_page, end_page, subcategory_url_string, subcategory_title):\n",
    "    url = 'https://fineartamerica.com/art/{}/owl'.format(subcategory_url_string)\n",
    "    \n",
    "    print('Checking if {} exists.'.format(directory))\n",
    "    if not os.path.isdir(directory):\n",
    "        print('Creating {}.'.format(directory))\n",
    "        os.mkdir(directory)\n",
    "        print('{} created.'.format(directory))\n",
    "    else:\n",
    "        print('{} exists.'.format(directory))\n",
    "    \n",
    "    directory_tail = 'Page_{:03d}-{:03d}'.format(start_page, end_page)\n",
    "    subdirectory = directory + '/' + directory_tail\n",
    "    if not os.path.isdir(subdirectory):\n",
    "        print('Creating subdirectory {}.'.format(subdirectory))\n",
    "        os.mkdir(subdirectory)\n",
    "        print('{} subdirectory created.'.format(subdirectory))\n",
    "    else:\n",
    "        print('Subdirectory {} exists.'.format(subdirectory))\n",
    "    \n",
    "    page_range = range(start_page, end_page + 1)\n",
    "    \n",
    "    for page in page_range:\n",
    "        time.sleep(0.1)\n",
    "        url_tail = '?page={}'.format(page)\n",
    "        print('Scraping page {}'.format(page))\n",
    "        response = requests.get(url + url_tail)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        image_tags = soup.find_all('img')\n",
    "        image_tags_cleaned = [x for x in image_tags if 'data-src' in\\\n",
    "                              x.attrs.keys() and 'artworkimages' in x['data-src']]\n",
    "        \n",
    "        for index, image in enumerate(image_tags_cleaned):\n",
    "            time.sleep(0.1)\n",
    "            img = Image.open(requests.get(image['data-src'], stream = True).raw)\n",
    "            print('Saving image {} of {} to {}.'.format(index + 1, len(image_tags_cleaned), subdirectory))\n",
    "            img_name = 'FineArtAmerica{}_Page_{:03d}_Image_{:03d}.{}'.format(subcategory_title,\n",
    "                                                                             page, index + 1, img.format)\n",
    "            img.save(subdirectory + '/' + img_name)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0cd913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory = '../data/raw/vectorstock'\n",
    "# scrape_vectorstock(directory, 1, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28caa4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/vectorstock'\n",
    "# scrape_vectorstock(directory, 22, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9c91a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory = '../data/raw/adobe_sketch'\n",
    "# subcategory = 'sketch'\n",
    "# subcategory_title = 'Sketch'\n",
    "# scrape_adobe(directory, 1, 50, subcategory, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b7e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/adobe_sketch'\n",
    "# subcategory = 'sketch'\n",
    "# subcategory_title = 'Sketch'\n",
    "# scrape_adobe(directory, 51, 100, subcategory, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1afed821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/adobe_drawings'\n",
    "# subcategory = 'drawing'\n",
    "# subcategory_title = 'Drawings'\n",
    "# scrape_adobe(directory, 1, 50, subcategory, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "902e397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/adobe_drawings'\n",
    "# subcategory = 'drawing'\n",
    "# subcategory_title = 'Drawings'\n",
    "# scrape_adobe(directory, 51, 100, subcategory, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c21ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory = '../data/raw/fineartamerica_drawings'\n",
    "# subcategory_url = 'drawings'\n",
    "# subcategory_title = 'Drawings'\n",
    "# scrape_fineartamerica(directory, 1, 35, subcategory_url, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a096517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/fineartamerica_digital'\n",
    "# subcategory_url = 'digital+art'\n",
    "# subcategory_title = 'Digital'\n",
    "# scrape_fineartamerica(directory, 1, 35, subcategory_url, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c4a1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/fineartamerica_paintings'\n",
    "# subcategory_url = 'paintings'\n",
    "# subcategory_title = 'Paintings'\n",
    "# scrape_fineartamerica(directory, 1, 35, subcategory_url, subcategory_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
