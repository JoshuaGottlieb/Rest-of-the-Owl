{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c73132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ee04fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_vectorstock(directory, start_page, end_page):\n",
    "    url = 'https://www.vectorstock.com/royalty-free-vectors/owl-sketch-vectors'\n",
    "    \n",
    "    print('Checking if {} exists.'.format(directory))\n",
    "    if not os.path.isdir(directory):\n",
    "        print('Creating {}.'.format(directory))\n",
    "        os.mkdir(directory)\n",
    "        print('{} created.'.format(directory))\n",
    "    else:\n",
    "        print('{} exists.'.format(directory))\n",
    "    \n",
    "    directory_tail = 'Page_{:02d}-{:02d}'.format(start_page, end_page)\n",
    "    subdirectory = directory + '/' + directory_tail\n",
    "    if not os.path.isdir(subdirectory):\n",
    "        print('Creating subdirectory {}.'.format(subdirectory))\n",
    "        os.mkdir(subdirectory)\n",
    "        print('{} subdirectory created.'.format(subdirectory))\n",
    "    else:\n",
    "        print('Subdirectory {} exists.'.format(subdirectory))\n",
    "    \n",
    "    page_range = range(start_page, end_page + 1)\n",
    "    \n",
    "    for page in page_range:\n",
    "        time.sleep(0.1)\n",
    "        url_tail = '-page_{}'.format(page)\n",
    "        print('Scraping page {}'.format(page))\n",
    "        response = requests.get(url + url_tail)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        image_tags = soup.find_all('img')\n",
    "        \n",
    "        for index, image in enumerate(image_tags):\n",
    "            time.sleep(0.1)\n",
    "            print('Saving image {} of {} to {}.'.format(index + 1, len(image_tags), subdirectory))\n",
    "            img = Image.open(requests.get(image['src'], stream = True).raw)\n",
    "            img_name = 'VectorStock_Page_{:02d}_Image_{:03d}.{}'.format(page, index + 1, img.format)\n",
    "            img.save(subdirectory + '/' + img_name)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "103d76a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory = '../data/raw/vectorstock'\n",
    "# scrape_vectorstock(directory, 2, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2f793f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/vectorstock'\n",
    "# scrape_vectorstock(directory, 22, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc907f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf501c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_adobe(directory, start_page, end_page):\n",
    "    url = 'https://stock.adobe.com/search/images?&k=owl+sketch'\n",
    "    \n",
    "    print('Checking if {} exists.'.format(directory))\n",
    "    if not os.path.isdir(directory):\n",
    "        print('Creating {}.'.format(directory))\n",
    "        os.mkdir(directory)\n",
    "        print('{} created.'.format(directory))\n",
    "    else:\n",
    "        print('{} exists.'.format(directory))\n",
    "    \n",
    "    directory_tail = 'Page_{:03d}-{:03d}'.format(start_page, end_page)\n",
    "    subdirectory = directory + '/' + directory_tail\n",
    "    if not os.path.isdir(subdirectory):\n",
    "        print('Creating subdirectory {}.'.format(subdirectory))\n",
    "        os.mkdir(subdirectory)\n",
    "        print('{} subdirectory created.'.format(subdirectory))\n",
    "    else:\n",
    "        print('Subdirectory {} exists.'.format(subdirectory))\n",
    "    \n",
    "    page_range = range(start_page, end_page + 1)\n",
    "    \n",
    "    for page in page_range:\n",
    "        time.sleep(0.1)\n",
    "        url_tail = '&search_page={}'.format(page)\n",
    "        print('Scraping page {}'.format(page))\n",
    "        response = requests.get(url + url_tail)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        image_tags = soup.find_all('img')\n",
    "        image_tags_cleaned = [x for x in image_tags if 'data-lazy' in\\\n",
    "                              x.attrs.keys() or x['src'].endswith('.jpg')]\n",
    "        \n",
    "        for index, image in enumerate(image_tags_cleaned):\n",
    "            time.sleep(0.1)\n",
    "            if 'data-lazy' in image.attrs.keys():\n",
    "                img = Image.open(requests.get(image['data-lazy'], stream = True).raw)\n",
    "            elif image['src'].endswith('.jpg'):\n",
    "                img = Image.open(requests.get(image['src'], stream = True).raw)\n",
    "            print('Saving image {} of {} to {}.'.format(index + 1, len(image_tags_cleaned), subdirectory))\n",
    "            img_name = 'AdobeStock_Page_{:03d}_Image_{:03d}.{}'.format(page, index + 1, img.format)\n",
    "            img.save(subdirectory + '/' + img_name)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "886225e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory = '../data/raw/adobe'\n",
    "# scrape_adobe(directory, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c852a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/raw/adobe'\n",
    "# scrape_adobe(directory, 51, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47ad98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fineartamerica(directory, start_page, end_page, subcategory_url_string, subcategory_title):\n",
    "    url = 'https://fineartamerica.com/art/{}/owl'.format(subcateogry_url_string)\n",
    "    \n",
    "    print('Checking if {} exists.'.format(directory))\n",
    "    if not os.path.isdir(directory):\n",
    "        print('Creating {}.'.format(directory))\n",
    "        os.mkdir(directory)\n",
    "        print('{} created.'.format(directory))\n",
    "    else:\n",
    "        print('{} exists.'.format(directory))\n",
    "    \n",
    "    directory_tail = 'Page_{:03d}-{:03d}'.format(start_page, end_page)\n",
    "    subdirectory = directory + '/' + directory_tail\n",
    "    if not os.path.isdir(subdirectory):\n",
    "        print('Creating subdirectory {}.'.format(subdirectory))\n",
    "        os.mkdir(subdirectory)\n",
    "        print('{} subdirectory created.'.format(subdirectory))\n",
    "    else:\n",
    "        print('Subdirectory {} exists.'.format(subdirectory))\n",
    "    \n",
    "    page_range = range(start_page, end_page + 1)\n",
    "    \n",
    "    for page in page_range:\n",
    "        time.sleep(0.1)\n",
    "        url_tail = '?page={}'.format(page)\n",
    "        print('Scraping page {}'.format(page))\n",
    "        response = requests.get(url + url_tail)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        image_tags = soup.find_all('img')\n",
    "        image_tags_cleaned = [x for x in image_tags if 'data-src' in\\\n",
    "                              x.attrs.keys() and 'artworkimages' in x['data-src']]\n",
    "        \n",
    "        for index, image in enumerate(image_tags_cleaned):\n",
    "            time.sleep(0.1)\n",
    "            img = Image.open(requests.get(image['data-src'], stream = True).raw)\n",
    "            print('Saving image {} of {} to {}.'.format(index + 1, len(image_tags_cleaned), subdirectory))\n",
    "            img_name = 'FineArtAmerica{}_Page_{:03d}_Image_{:03d}.{}'.format(subcategory_title,\n",
    "                                                                             page, index + 1, img.format)\n",
    "            img.save(subdirectory + '/' + img_name)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7077951e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory = '../data/raw/fineartamerica_drawings'\n",
    "# subcategory_url = 'drawings'\n",
    "# subcategory_title = 'Drawings'\n",
    "# scrape_fineartamerica_drawings(directory, 1, 35, subcategory_url, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/raw/fineartamerica_digital'\n",
    "subcategory_url = 'digital+art'\n",
    "subcategory_title = 'Digital'\n",
    "scrape_fineartamerica_drawings(directory, 1, 35, subcategory_url, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a511f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/raw/fineartamerica_paintings'\n",
    "subcategory_url = 'paintings'\n",
    "subcategory_title = 'Paintings'\n",
    "scrape_fineartamerica_drawings(directory, 1, 35, subcategory_url, subcategory_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d347d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf307bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba767a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd2c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d68c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
