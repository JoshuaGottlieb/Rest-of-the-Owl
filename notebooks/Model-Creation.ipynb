{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397fec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d830703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_graph = [\"<tf.Variable 'generator/encoder_1/conv/filter:0' shape=(4, 4, 3, 64) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_2/conv/filter:0' shape=(4, 4, 64, 128) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_2/batchnorm/offset:0' shape=(128,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_2/batchnorm/scale:0' shape=(128,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_3/conv/filter:0' shape=(4, 4, 128, 256) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_3/batchnorm/offset:0' shape=(256,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_3/batchnorm/scale:0' shape=(256,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_4/conv/filter:0' shape=(4, 4, 256, 512) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_4/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_4/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_5/conv/filter:0' shape=(4, 4, 512, 512) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_5/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_5/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_6/conv/filter:0' shape=(4, 4, 512, 512) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_6/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_6/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_7/conv/filter:0' shape=(4, 4, 512, 512) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_7/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_7/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_8/conv/filter:0' shape=(4, 4, 512, 512) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_8/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/encoder_8/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_8/deconv/filter:0' shape=(4, 4, 512, 512) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_8/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_8/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_7/deconv/filter:0' shape=(4, 4, 512, 1024) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_7/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_7/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_6/deconv/filter:0' shape=(4, 4, 512, 1024) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_6/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_6/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_5/deconv/filter:0' shape=(4, 4, 512, 1024) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_5/batchnorm/offset:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_5/batchnorm/scale:0' shape=(512,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_4/deconv/filter:0' shape=(4, 4, 256, 1024) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_4/batchnorm/offset:0' shape=(256,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_4/batchnorm/scale:0' shape=(256,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_3/deconv/filter:0' shape=(4, 4, 128, 512) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_3/batchnorm/offset:0' shape=(128,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_3/batchnorm/scale:0' shape=(128,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_2/deconv/filter:0' shape=(4, 4, 64, 256) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_2/batchnorm/offset:0' shape=(64,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_2/batchnorm/scale:0' shape=(64,) dtype=float32_ref>\",\n",
    " \"<tf.Variable 'generator/decoder_1/deconv/filter:0' shape=(4, 4, 3, 128) dtype=float32_ref>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    with tf.name_scope(\"preprocess\"):\n",
    "        # [0, 1] => [-1, 1]\n",
    "        return image * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(image):\n",
    "    with tf.name_scope(\"deprocess\"):\n",
    "        # [-1, 1] => [0, 1]\n",
    "        return (image + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(image):\n",
    "    assertion = tf.assert_equal(tf.shape(image)[-1], 3, message=\"image must have 3 color channels\")\n",
    "    with tf.control_dependencies([assertion]):\n",
    "        image = tf.identity(image)\n",
    "\n",
    "    if image.get_shape().ndims not in (3, 4):\n",
    "        raise ValueError(\"image must be either 3 or 4 dimensions\")\n",
    "\n",
    "    # make the last dimension 3 so that you can unstack the colors\n",
    "    shape = list(image.get_shape())\n",
    "    shape[-1] = 3\n",
    "    image.set_shape(shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, a):\n",
    "    with tf.name_scope(\"lrelu\"):\n",
    "        # adding these together creates the leak part and linear part\n",
    "        # then cancels them out by subtracting/adding an absolute value term\n",
    "        # leak: a*x/2 - a*abs(x)/2\n",
    "        # linear: x/2 + abs(x)/2\n",
    "\n",
    "        # this block looks like it has 2 inputs on the graph unless we do this\n",
    "        x = tf.identity(x)\n",
    "        return (0.5 * (1 + a)) * x + (0.5 * (1 - a)) * tf.abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm(input):\n",
    "    with tf.variable_scope(\"batchnorm\"):\n",
    "        # this block looks like it has 3 inputs on the graph unless we do this\n",
    "        input = tf.identity(input)\n",
    "\n",
    "        channels = input.get_shape()[3]\n",
    "        offset = tf.get_variable(\"offset\", [channels], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "        scale = tf.get_variable(\"scale\", [channels], dtype=tf.float32,\n",
    "                                initializer=tf.random_normal_initializer(1.0, 0.02))\n",
    "        mean, variance = tf.nn.moments(input, axes=[0, 1, 2], keep_dims=False)\n",
    "        variance_epsilon = 1e-5\n",
    "        normalized = tf.nn.batch_normalization(input, mean, variance, offset, scale, variance_epsilon=variance_epsilon)\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f64b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(generator_inputs, generator_outputs_channels):\n",
    "    layers = []\n",
    "\n",
    "    # encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]\n",
    "    with tf.variable_scope(\"encoder_1\"):\n",
    "        output = conv(generator_inputs, a.ngf, stride=2)\n",
    "        layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        a.ngf * 2,\n",
    "        a.ngf * 4,\n",
    "        a.ngf * 8,\n",
    "        a.ngf * 8,\n",
    "        a.ngf * 8,\n",
    "        a.ngf * 8,\n",
    "        a.ngf * 8,\n",
    "    ]\n",
    "\n",
    "    for out_channels in layer_specs:\n",
    "        with tf.variable_scope(\"encoder_%d\" % (len(layers) + 1)):\n",
    "            rectified = lrelu(layers[-1], 0.2)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]\n",
    "            convolved = conv(rectified, out_channels, stride=2)\n",
    "            output = batchnorm(convolved)\n",
    "            layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        (a.ngf * 8, 0.5),\n",
    "        (a.ngf * 8, 0.5),\n",
    "        (a.ngf * 8, 0.5),\n",
    "        (a.ngf * 8, 0.0),\n",
    "        (a.ngf * 4, 0.0),\n",
    "        (a.ngf * 2, 0.0),\n",
    "        (a.ngf, 0.0),\n",
    "    ]\n",
    "\n",
    "    num_encoder_layers = len(layers)\n",
    "    for decoder_layer, (out_channels, dropout) in enumerate(layer_specs):\n",
    "        skip_layer = num_encoder_layers - decoder_layer - 1\n",
    "        with tf.variable_scope(\"decoder_%d\" % (skip_layer + 1)):\n",
    "            if decoder_layer == 0:\n",
    "                # first decoder layer doesn't have skip connections\n",
    "                # since it is directly connected to the skip_layer\n",
    "                input = layers[-1]\n",
    "            else:\n",
    "                input = tf.concat([layers[-1], layers[skip_layer]], axis=3)\n",
    "\n",
    "            rectified = tf.nn.relu(input)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]\n",
    "            output = deconv(rectified, out_channels)\n",
    "            output = batchnorm(output)\n",
    "\n",
    "            if dropout > 0.0:\n",
    "                output = tf.nn.dropout(output, keep_prob=1 - dropout)\n",
    "\n",
    "            layers.append(output)\n",
    "\n",
    "    # decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]\n",
    "    with tf.variable_scope(\"decoder_1\"):\n",
    "        input = tf.concat([layers[-1], layers[0]], axis=3)\n",
    "        rectified = tf.nn.relu(input)\n",
    "        output = deconv(rectified, generator_outputs_channels)\n",
    "        output = tf.tanh(output)\n",
    "        layers.append(output)\n",
    "\n",
    "    return layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(discrim_inputs, discrim_targets):\n",
    "        n_layers = 3\n",
    "        layers = []\n",
    "\n",
    "        # 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]\n",
    "        input = tf.concat([discrim_inputs, discrim_targets], axis=3)\n",
    "\n",
    "        # layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]\n",
    "        with tf.variable_scope(\"layer_1\"):\n",
    "            convolved = conv(input, a.ndf, stride=2)\n",
    "            rectified = lrelu(convolved, 0.2)\n",
    "            layers.append(rectified)\n",
    "\n",
    "        # layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]\n",
    "        # layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]\n",
    "        # layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]\n",
    "        for i in range(n_layers):\n",
    "            with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "                out_channels = a.ndf * min(2 ** (i + 1), 8)\n",
    "                stride = 1 if i == n_layers - 1 else 2  # last layer here has stride 1\n",
    "                convolved = conv(layers[-1], out_channels, stride=stride)\n",
    "                normalized = batchnorm(convolved)\n",
    "                rectified = lrelu(normalized, 0.2)\n",
    "                layers.append(rectified)\n",
    "\n",
    "        # layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]\n",
    "        with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "            convolved = conv(rectified, out_channels=1, stride=1)\n",
    "            output = tf.sigmoid(convolved)\n",
    "            layers.append(output)\n",
    "\n",
    "        return layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e422de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_tv_loss(image):\n",
    "        loss_y = tf.nn.l2_loss(image[:, 1:, :, :] - image[:, :-1, :, :])\n",
    "        loss_x = tf.nn.l2_loss(image[:, :, 1:, :] - image[:, :, :-1, :])\n",
    "        loss = 2 * (loss_y + loss_x)\n",
    "        loss = tf.cast(loss, tf.float32)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1edd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_loss(image , vgg):\n",
    "        vgg.build(image)\n",
    "        loss = vgg.conv3_3\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de010b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"generator\") as scope:\n",
    "        out_channels = int(targets.get_shape()[-1])\n",
    "        outputs = create_generator(inputs, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs, targets, net1,net2):\n",
    "    with tf.variable_scope(\"generator\") as scope:\n",
    "        out_channels = int(targets.get_shape()[-1])\n",
    "        outputs = create_generator(inputs, out_channels)\n",
    "\n",
    "    # create two copies of discriminator, one for real pairs and one for fake pairs\n",
    "    # they share the same underlying variables\n",
    "    with tf.name_scope(\"real_discriminator\"):\n",
    "        with tf.variable_scope(\"discriminator\"):\n",
    "            # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "            predict_real = create_discriminator(inputs, targets)\n",
    "\n",
    "    with tf.name_scope(\"fake_discriminator\"):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=True):\n",
    "            # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "            predict_fake = create_discriminator(inputs, outputs)\n",
    "\n",
    "    with tf.name_scope(\"discriminator_loss\"):\n",
    "        # minimizing -tf.log will try to get inputs to 1\n",
    "        # predict_real => 1\n",
    "        # predict_fake => 0\n",
    "        discrim_loss = tf.reduce_mean(predict_fake-predict_real)\n",
    "        #  with tf.name_scope(\"\"):\n",
    "    with tf.name_scope(\"generator_loss\"):\n",
    "        # predict_fake => 1\n",
    "        # abs(targets - outputs) => 0\n",
    "        gen_loss_GAN = -tf.reduce_mean(predict_fake)\n",
    "        gen_loss_L1 = tf.reduce_mean(tf.abs(targets - outputs))\n",
    "        gen_loss_tv = tf.reduce_mean(tf.sqrt(tf.nn.l2_loss(sum_tv_loss(outputs))))\n",
    "        gen_loss_f = tf.reduce_mean(tf.sqrt(tf.nn.l2_loss(feature_loss(targets,net1) - feature_loss(outputs,net2))))\n",
    "        gen_loss = gen_loss_GAN * a.gan_weight + gen_loss_L1 * a.l1_weight + gen_loss_tv * a.tv_weight + gen_loss_f * a.f_weight\n",
    "\n",
    "    with tf.name_scope(\"discriminator_train\"):\n",
    "        discrim_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n",
    "        discrim_optim = tf.train.RMSPropOptimizer(a.lr, a.beta1)\n",
    "        discrim_grads_and_vars = discrim_optim.compute_gradients(discrim_loss, var_list=discrim_tvars)\n",
    "        discrim_train = discrim_optim.apply_gradients(discrim_grads_and_vars)\n",
    "        clip_vars = [tf.assign(var, tf.clip_by_value(var, -0.02, 0.02)) for var in discrim_tvars]\n",
    "        tuple_vars = tf.tuple(clip_vars, control_inputs=[discrim_train])\n",
    "\n",
    "\n",
    "    with tf.name_scope(\"generator_train\"):\n",
    "        with tf.control_dependencies(tuple_vars):\n",
    "            gen_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n",
    "            gen_optim = tf.train.RMSPropOptimizer(a.lr, a.beta1)\n",
    "            gen_grads_and_vars = gen_optim.compute_gradients(gen_loss, var_list=gen_tvars)\n",
    "            gen_train = gen_optim.apply_gradients(gen_grads_and_vars)\n",
    "\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "    update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1, gen_loss_tv, gen_loss_f])\n",
    "\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "    incr_global_step = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "    return Model(\n",
    "        predict_real=predict_real,\n",
    "        predict_fake=predict_fake,\n",
    "        discrim_loss=ema.average(discrim_loss),\n",
    "        discrim_grads_and_vars=discrim_grads_and_vars,\n",
    "        gen_loss_GAN=ema.average(gen_loss_GAN),\n",
    "        gen_loss_L1=ema.average(gen_loss_L1),\n",
    "        gen_loss_tv=ema.average(gen_loss_tv),\n",
    "        gen_loss_f=ema.average(gen_loss_f),\n",
    "        gen_grads_and_vars=gen_grads_and_vars,\n",
    "        outputs=outputs,\n",
    "        train=tf.group(update_losses, incr_global_step, gen_train),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a3dc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Conv2DTranspose, BatchNormalization, Dropout, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e19d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    lrelu = LeakyReLU(alpha = 0.2)\n",
    "    inputs = Input(shape = (256, 256, 1))\n",
    "    \n",
    "    encoder_1 = Conv2D(32, (4, 4), (2, 2), padding = 'same')(inputs)\n",
    "    \n",
    "    encoder_2 = Conv2D(64, (4, 4), (2, 2), activation = lrelu, padding = 'same')(encoder_1)\n",
    "    encoder_2 = BatchNormalization()(encoder_2)\n",
    "    \n",
    "    encoder_3 = Conv2D(128, (4, 4), (2, 2), activation = lrelu, padding = 'same')(encoder_2)\n",
    "    encoder_3 = BatchNormalization()(encoder_3)\n",
    "    \n",
    "    encoder_4 = Conv2D(256, (4, 4), (2, 2), activation = lrelu, padding = 'same')(encoder_3)\n",
    "    encoder_4 = BatchNormalization()(encoder_4)\n",
    "    \n",
    "    encoder_5 = Conv2D(256, (4, 4), (2, 2), activation = lrelu, padding = 'same')(encoder_4)\n",
    "    encoder_5 = BatchNormalization()(encoder_5)\n",
    "    \n",
    "    encoder_6 = Conv2D(256, (4, 4), (2, 2), activation = lrelu, padding = 'same')(encoder_5)\n",
    "    encoder_6 = BatchNormalization()(encoder_6)\n",
    "    \n",
    "    encoder_7 = Conv2D(256, (4, 4), (2, 2), activation = lrelu, padding = 'same')(encoder_6)\n",
    "    encoder_7 = BatchNormalization()(encoder_7)\n",
    "    \n",
    "    encoder_8 = Conv2D(256, (4, 4), (2, 2), activation = lrelu, padding = 'same')(encoder_7)\n",
    "    encoder_8 = BatchNormalization()(encoder_8)\n",
    "    \n",
    "    decoder_8 = Conv2DTranspose(256, (4, 4), (2, 2), activation = 'relu', padding = 'same')(encoder_8)\n",
    "    decoder_8 = BatchNormalization()(decoder_8)\n",
    "    decoder_8 = Dropout(0.5)(decoder_8)\n",
    "    \n",
    "    decoder_7 = Conv2DTranspose(256, (4, 4), (2, 2), activation = 'relu', padding = 'same')\\\n",
    "                        (concatenate([decoder_8, encoder_7], axis = -1))\n",
    "    decoder_7 = BatchNormalization()(decoder_7)\n",
    "    decoder_7 = Dropout(0.5)(decoder_7)\n",
    "    \n",
    "    decoder_6 = Conv2DTranspose(256, (4, 4), (2, 2), activation = 'relu', padding = 'same')\\\n",
    "                        (concatenate([decoder_7, encoder_6], axis = -1))\n",
    "    decoder_6 = BatchNormalization()(decoder_6)\n",
    "    decoder_6 = Dropout(0.5)(decoder_6)\n",
    "    \n",
    "    decoder_5 = Conv2DTranspose(256, (4, 4), (2, 2), activation = 'relu', padding = 'same')\\\n",
    "                        (concatenate([decoder_6, encoder_5], axis = -1))\n",
    "    decoder_5 = BatchNormalization()(decoder_5)\n",
    "    \n",
    "    decoder_4 = Conv2DTranspose(128, (4, 4), (2, 2), activation = 'relu', padding = 'same')\\\n",
    "                        (concatenate([decoder_5, encoder_4], axis = -1))\n",
    "    decoder_4 = BatchNormalization()(decoder_4)\n",
    "    \n",
    "    decoder_3 = Conv2DTranspose(64, (4, 4), (2, 2), activation = 'relu', padding = 'same')\\\n",
    "                        (concatenate([decoder_4, encoder_3], axis = -1))\n",
    "    decoder_3 = BatchNormalization()(decoder_3)\n",
    "    \n",
    "    decoder_2 = Conv2DTranspose(32, (4, 4), (2, 2), activation = 'relu', padding = 'same')\\\n",
    "                        (concatenate([decoder_3, encoder_2], axis = -1))\n",
    "    decoder_2 = BatchNormalization()(decoder_2)\n",
    "    \n",
    "    decoder_1 = Conv2DTranspose(1, (4, 4), (2, 2), activation = 'relu', padding = 'same')\\\n",
    "                        (concatenate([decoder_2, encoder_1], axis = -1))\n",
    "    \n",
    "    outputs = Activation('tanh')(decoder_1)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f15265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    inputs = Input(shape = (256, 256, 2))\n",
    "    lrelu = LeakyReLU(alpha = 0.2)\n",
    "    \n",
    "    layer_1 = Conv2D(32, (4, 4), (2, 2), activation = lrelu, padding = 'same')(inputs)\n",
    "    \n",
    "    layer_2 = Conv2D(64, (4, 4), (2, 2), activation = lrelu, padding = 'same')(layer_1)\n",
    "    layer_2 = BatchNormalization()(layer_2)\n",
    "    \n",
    "    layer_3 = Conv2D(128, (4, 4), (2, 2), activation = lrelu, padding = 'same')(layer_2)\n",
    "    layer_3 = BatchNormalization()(layer_3)\n",
    "    \n",
    "    layer_4 = Conv2D(256, (4, 4), (1, 1), activation = lrelu, padding = 'same')(layer_3)\n",
    "    layer_4 = BatchNormalization()(layer_4)\n",
    "    \n",
    "    layer_4 = Conv2D(1, (4, 4), (1, 1), activation = lrelu, padding = 'same')(layer_4)\n",
    "    \n",
    "    outputs = Activation('sigmoid')(layer_4)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecad6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyModel, self).__init__(*args, **kwargs)\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "    def compute_loss(self, x, y, y_pred, sample_weight):\n",
    "        loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
    "        loss += tf.add_n(self.losses)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return loss\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        self.loss_tracker.reset_states()\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7befac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(predict_real, predict_fake):\n",
    "    return tf.reduce_mean(predict_fake - predict_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(predict_fake, targets, outputs, net1, net2):\n",
    "    gen_loss_GAN = -tf.reduce_mean(predict_fake)\n",
    "    gen_loss_L1 = tf.reduce_mean(tf.abs(targets - outputs))\n",
    "    gen_loss_tv = tf.reduce_mean(tf.sqrt(tf.nn.l2_loss(sum_tv_loss(outputs))))\n",
    "    gen_loss_f = tf.reduce_mean(tf.sqrt(tf.nn.l2_loss(feature_loss(targets,net1) - feature_loss(outputs,net2))))\n",
    "    gen_loss = gen_loss_GAN + (gen_loss_L1 * 10) + (gen_loss_tv * 1e-5) + (gen_loss_f * 1e-4)\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator()\n",
    "discriminator = create_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a44116",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    \n",
    "    outputs = create_generator(inputs, out_channels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb62e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d28517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdd0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a829e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc3fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(batch_input, out_channels, stride):\n",
    "    with tf.variable_scope(\"conv\"):\n",
    "        in_channels = batch_input.get_shape()[3]\n",
    "        filter = tf.get_variable(\"filter\", [4, 4, in_channels, out_channels], dtype=tf.float32,\n",
    "                                 initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        # [batch, in_height, in_width, in_channels], [filter_width, filter_height, in_channels, out_channels]\n",
    "        #     => [batch, out_height, out_width, out_channels]\n",
    "        padded_input = tf.pad(batch_input, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"CONSTANT\")\n",
    "        conv = tf.nn.conv2d(padded_input, filter, [1, stride, stride, 1], padding=\"VALID\")\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b4f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7b553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(batch_input, out_channels):\n",
    "    with tf.variable_scope(\"deconv\"):\n",
    "        batch, in_height, in_width, in_channels = [int(d) for d in batch_input.get_shape()]\n",
    "        filter = tf.get_variable(\"filter\", [4, 4, out_channels, in_channels], dtype=tf.float32,\n",
    "                                 initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        # [batch, in_height, in_width, in_channels], [filter_width, filter_height, out_channels, in_channels]\n",
    "        #     => [batch, out_height, out_width, out_channels]\n",
    "        conv = tf.nn.conv2d_transpose(batch_input, filter, [batch, in_height * 2, in_width * 2, out_channels],\n",
    "                                      [1, 2, 2, 1], padding=\"SAME\")\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d76f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405eafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecfd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d88607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
