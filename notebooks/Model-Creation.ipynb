{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "902c2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Conv2DTranspose, BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.keras.layers import ReLU, Resizing, Rescaling, concatenate\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "import keras\n",
    "from tensorflow.io import read_file, decode_jpeg\n",
    "from tensorflow import cast, shape\n",
    "from tensorflow.image import resize, resize_with_pad, ResizeMethod\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow import expand_dims\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75edc4d2",
   "metadata": {},
   "source": [
    "# Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4df5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, strides, apply_batchnorm = True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    # Make sequential model\n",
    "    result = Sequential()\n",
    "    # Add Conv2D\n",
    "    result.add(Conv2D(filters, size, strides = strides, padding = 'same',\n",
    "                             kernel_initializer = initializer, use_bias = False))\n",
    "\n",
    "    # Optionally add batchnorm\n",
    "    if apply_batchnorm:\n",
    "        result.add(BatchNormalization())\n",
    "\n",
    "    # Add leaky relu\n",
    "    result.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e115b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, strides, apply_dropout = False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    # Make sequential model\n",
    "    result = Sequential()\n",
    "    # Add deconv layer (conv2dtranspose)\n",
    "    result.add(Conv2DTranspose(filters, size, strides = strides,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer = initializer,\n",
    "                                    use_bias = False))\n",
    "\n",
    "    # Add batchnorm\n",
    "    result.add(BatchNormalization())\n",
    "\n",
    "    # Optionally add dropout\n",
    "    if apply_dropout:\n",
    "        result.add(Dropout(0.5))\n",
    "    \n",
    "    # Add relu\n",
    "    result.add(ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02df6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    inputs = Input(shape = [256, 256, 1])\n",
    "    \n",
    "    # Define downsampling layers\n",
    "    down_stack = [\n",
    "        downsample(64, 4, 2, apply_batchnorm = False),\n",
    "        downsample(128, 4, 2),\n",
    "        downsample(256, 4, 2),\n",
    "        downsample(512, 4, 2),\n",
    "        downsample(512, 4, 2),\n",
    "        downsample(512, 4, 2),\n",
    "        downsample(512, 4, 2),\n",
    "        downsample(512, 4, 2)\n",
    "    ]\n",
    "    \n",
    "    # Define upsampling layers\n",
    "    up_stack = [\n",
    "        upsample(512, 4, 2, apply_dropout = True),\n",
    "        upsample(512, 4, 2, apply_dropout = True),\n",
    "        upsample(512, 4, 2, apply_dropout = True),\n",
    "        upsample(512, 4, 2),\n",
    "        upsample(256, 4, 2),\n",
    "        upsample(128, 4, 2),\n",
    "        upsample(64, 4, 2),\n",
    "    ]\n",
    "    \n",
    "    # Last layer\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(1, 4, strides = 2, padding = 'same',\n",
    "                                           kernel_initializer = initializer, activation = 'tanh')\n",
    "    \n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs = inputs, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c592dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = [256, 256, 1], name = 'sketch')\n",
    "    tar = tf.keras.layers.Input(shape = [256, 256, 1], name = 'target')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar])\n",
    "\n",
    "    down1 = downsample(64, 4, 2, False)(x)\n",
    "    down2 = downsample(128, 4, 2)(down1)\n",
    "    down3 = downsample(256, 4, 2)(down2)\n",
    "    down4 = downsample(512, 4, 1)(down3)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides = 1, kernel_initializer = initializer)(down4)\n",
    "\n",
    "    return tf.keras.Model(inputs = [inp, tar], outputs = last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3aff15",
   "metadata": {},
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed12a04",
   "metadata": {},
   "source": [
    "## pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317f61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss_pix2pix(disc_generated_output, gen_output, target, loss_object):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # Mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (100 * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d97d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss_pix2pix(disc_real_output, disc_generated_output, loss_object):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ca67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_pix2pix(input_image, target, generator, discriminator, gen_optimizer, discrim_optimizer, loss_obj):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss_pix2pix(disc_generated_output, gen_output,\n",
    "                                                                           target, loss_obj)\n",
    "        disc_loss = discriminator_loss_pix2pix(disc_real_output, disc_generated_output, loss_obj)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discrim_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c76f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pix2pix(train_ds, test_ds, epochs, generator, discriminator, gen_optimizer, discrim_optimizer, loss_obj, log_file, model_dir, starting_epoch = 0, save = True):\n",
    "\n",
    "    example_target, example_input = next(iter(test_ds.take(1)))\n",
    "    start = time.time()\n",
    "    epoch_range = range(starting_epoch, starting_epoch + epochs)\n",
    "    \n",
    "    for epoch, _ in enumerate(epoch_range):\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        # Print time to process previous epoch\n",
    "        if (epoch + starting_epoch) != starting_epoch:\n",
    "            print(f'Time taken for epoch: {time.time() - start:.2f} sec\\n')\n",
    "\n",
    "        # Restart timer and display current results of training    \n",
    "        start = time.time()\n",
    "        generate_images(generator, example_input, example_target)\n",
    "        print(f'Epoch: {epoch + starting_epoch + 1}')\n",
    "        \n",
    "        # Initialize empty array for losses\n",
    "        train_losses = np.zeros(4)\n",
    "        \n",
    "        # Train step\n",
    "        for (target, sketch) in train_ds:\n",
    "            train_losses += train_step_pix2pix(sketch, target,\n",
    "                                               generator, discriminator,\n",
    "                                               gen_optimizer, discrim_optimizer, loss_obj)\n",
    "\n",
    "        if save:\n",
    "            # Log losses\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'Epoch: {epoch + starting_epoch + 1}, gen_total_loss: {train_losses[0]:0.3f}, gen_gan_loss: {train_losses[1]:0.3f}, '\n",
    "                        + f'gen_l1_loss: {train_losses[2]:0.3f}, disc_loss: {train_losses[3]:0.3f}\\n')\n",
    "\n",
    "            # Save models every 10 epochs        \n",
    "            if ((epoch + 1) % 10) == 0:\n",
    "                epoch_dir = f'{model_dir}/epoch_{epoch + starting_epoch + 1:03d}'\n",
    "                if not os.path.exists(epoch_dir):\n",
    "                    os.mkdir(epoch_dir)\n",
    "                generator.save(f'{epoch_dir}/generator.h5')\n",
    "                discriminator.save(f'{epoch_dir}/discriminator.h5')\n",
    "                with open(f'{epoch_dir}/gen_optim_config.pickle', 'wb') as f:\n",
    "                    pickle.dump(gen_optimizer.get_config(), f)\n",
    "                with open(f'{epoch_dir}/discrim_optim_config.pickle', 'wb') as f:\n",
    "                    pickle.dump(discrim_optimizer.get_config(), f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6413c",
   "metadata": {},
   "source": [
    "## Autopainter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37227e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_tv_loss(image):\n",
    "    loss_y = tf.nn.l2_loss(image[:, 1:, :, :] - image[:, :-1, :, :])\n",
    "    loss_x = tf.nn.l2_loss(image[:, :, 1:, :] - image[:, :, :-1, :])\n",
    "    loss = 2 * (loss_y + loss_x)\n",
    "    loss = tf.cast(loss, tf.float32)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9295aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_loss(image, vgg):\n",
    "    model = Model(inputs = vgg.inputs, outputs = vgg.layers[9].output)\n",
    "    img = tf.reshape(image, [image.shape[-3], image.shape[-2], image.shape[-1]])\n",
    "    img = tf.image.grayscale_to_rgb(img)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = expand_dims(img, axis = 0)\n",
    "    img = preprocess_input(img)\n",
    "    feature_maps = model(img)\n",
    "    \n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85617534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss_autopainter(disc_real_output, disc_generated_output):\n",
    "    loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "    real_loss = loss_obj(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_obj(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665fd632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss_autopainter(disc_generated_output, gen_output, target, net):\n",
    "    gen_loss_GAN = tf.keras.losses.BinaryCrossentropy(from_logits = True)(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    gen_loss_L1 = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    gen_loss_tv = tf.reduce_mean(tf.sqrt(tf.nn.l2_loss(sum_tv_loss(gen_output))))\n",
    "    gen_loss_f = tf.reduce_mean(tf.sqrt(tf.nn.l2_loss(feature_loss(target, net) - feature_loss(gen_output, net))))\n",
    "    gen_total_loss = gen_loss_GAN + (gen_loss_L1 * 10) + (gen_loss_tv * 1e-5) + (gen_loss_f * 1e-4)\n",
    "    \n",
    "    return gen_total_loss, gen_loss_GAN, gen_loss_L1, gen_loss_tv, gen_loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373c699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_autopainter(input_image, target, generator, discriminator, gen_optimizer, discrim_optimizer, net):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_loss_GAN, gen_loss_L1, gen_loss_tv, gen_loss_f =\\\n",
    "            generator_loss_autopainter(disc_generated_output, gen_output, target, net)\n",
    "        disc_loss = discriminator_loss_autopainter(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discrim_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "    return gen_total_loss, gen_loss_GAN, gen_loss_L1, gen_loss_tv, gen_loss_f, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f60283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_autopainter(train_ds, test_ds, epochs, generator, discriminator, gen_optimizer,\n",
    "                    discrim_optimizer, net, log_file, model_dir, starting_epoch = 0, save = True):\n",
    "\n",
    "    example_target, example_input = next(iter(test_ds.take(1)))\n",
    "    start = time.time()\n",
    "    epoch_range = range(starting_epoch, starting_epoch + epochs)\n",
    "    \n",
    "    for epoch, _ in enumerate(epoch_range):\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        # Print time to process previous epoch\n",
    "        if (epoch + starting_epoch) != starting_epoch:\n",
    "            print(f'Time taken for epoch: {time.time() - start:.2f} sec\\n')\n",
    "\n",
    "        # Restart timer and display current results of training    \n",
    "        start = time.time()\n",
    "        generate_images(generator, example_input, example_target)\n",
    "        print(f'Epoch: {epoch + starting_epoch + 1}')\n",
    "        \n",
    "        # Initialize empty array for losses\n",
    "        train_losses = np.zeros(6)\n",
    "        \n",
    "        # Train step\n",
    "        for (target, sketch) in train_ds:\n",
    "            train_losses += train_step_autopainter(sketch, target, generator, discriminator,\n",
    "                                                   gen_optimizer, discrim_optimizer, net)\n",
    "            \n",
    "        if save:\n",
    "            # Log losses\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'Epoch: {epoch + starting_epoch + 1}, gen_total_loss: {train_losses[0]:0.3f}, '\n",
    "                        + f'gen_gan_loss: {train_losses[1]:0.3f}, ' + f'gen_l1_loss: {train_losses[2]:0.3f}, '\n",
    "                        + f'gen_tv_loss: {train_losses[3]:0.3f}, gen_f_loss: {train_losses[4]:0.3f}, '\n",
    "                        + f'disc_loss: {train_losses[5]:0.3f}\\n')\n",
    "\n",
    "            # Save models every 10 epochs        \n",
    "            if ((epoch + 1) % 10) == 0:\n",
    "                epoch_dir = f'{model_dir}/epoch_{epoch + starting_epoch + 1:03d}'\n",
    "                if not os.path.exists(epoch_dir):\n",
    "                    os.mkdir(epoch_dir)\n",
    "                generator.save(f'{epoch_dir}/generator.h5')\n",
    "                discriminator.save(f'{epoch_dir}/discriminator.h5')\n",
    "                with open(f'{epoch_dir}/gen_optim_config.pickle', 'wb') as f:\n",
    "                    pickle.dump(gen_optimizer.get_config(), f)\n",
    "                with open(f'{epoch_dir}/discrim_optim_config.pickle', 'wb') as f:\n",
    "                    pickle.dump(discrim_optimizer.get_config(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74873aa9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47661154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "  # Read and decode an image file to a uint8 tensor\n",
    "    pair = read_file(image_file)\n",
    "    pair = decode_jpeg(pair)\n",
    "    \n",
    "    w = shape(pair)[1]\n",
    "    w = w // 2\n",
    "    \n",
    "    image = pair[:, w:, :]\n",
    "    sketch = pair[:, :w, :]\n",
    "\n",
    "  # Convert both images to float32 tensors\n",
    "    sketch = cast(sketch, tf.float32)\n",
    "    image = cast(image, tf.float32)\n",
    "\n",
    "    return sketch, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23a30958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(sketch, image, height, width):\n",
    "    sketch_resized = resize_with_pad(sketch, height, width, method = ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image_resized = resize_with_pad(image, height, width, method = ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return sketch_resized, image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f81b726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the images to [0, 1]\n",
    "def normalize(sketch, image):\n",
    "    sketch_scaled = sketch / 255\n",
    "    image_scaled = image / 255\n",
    "\n",
    "    return sketch_scaled, image_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc95d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_sketch(image_file):\n",
    "    sketch, image = load(image_file)\n",
    "    sketch, image = resize(sketch, image, 256, 256)\n",
    "    sketch, image = normalize(sketch, image)\n",
    "\n",
    "    return sketch, image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f749c5",
   "metadata": {},
   "source": [
    "# Checkpointing and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_model_from_epoch(epoch_dir, model_type):\n",
    "    components = []\n",
    "    \n",
    "    generator = keras.models.load_model(f'{epoch_dir}/generator.h5')\n",
    "    discriminator = keras.models.load_model(f'{epoch_dir}/discriminator.h5')\n",
    "    \n",
    "    components.append(generator)\n",
    "    components.append(discriminator)\n",
    "\n",
    "    with open(f'{epoch_dir}/gen_optim_config.pickle', 'rb') as f:\n",
    "        gen_config = pickle.load(f)\n",
    "    with open(f'{epoch_dir}/discrim_optim_config.pickle', 'rb') as f:\n",
    "        discrim_config = pickle.load(f)\n",
    "\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-4).from_config(gen_config)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4).from_config(discrim_config)\n",
    "    components.append(generator_optimizer)\n",
    "    components.append(discriminator_optimizer)\n",
    "\n",
    "    if model_type == 'pix2pix':\n",
    "        loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "        components.append(loss_obj)\n",
    "    elif model_type == 'autopainter':\n",
    "        net = VGG16()\n",
    "        components.append(net)\n",
    "\n",
    "    log_file = f'{base_path}/logs/{model_type}/epoch_data.csv'\n",
    "    model_dir = f'{base_path}/models/{model_type}'\n",
    "    \n",
    "    components.append(log_file)\n",
    "    components.append(model_dir)\n",
    "\n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc433085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training = True)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(title[i])\n",
    "        # Getting the pixel values in the [0, 1] range to plot.\n",
    "#         plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.imshow(display_list[i][:, : , 0], cmap = 'gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "147ad124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input, model_name, save = False, base_path = '..'):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training = False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'{base_path}/logs/{model_name}/images/image_at_epoch_{epoch:04d}.png')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
